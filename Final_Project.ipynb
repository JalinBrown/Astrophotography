{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": [
    "# Astrophotography Pipeline: Andromeda\n",
    "\n",
    "This notebook walks through a full deep-sky processing pipeline:\n",
    "\n",
    "1. Configuration\n",
    "2. Calibration (CR2 to FITS, master calibration frames, calibrated lights)\n",
    "3. Alignment (register all light frames)\n",
    "4. Stacking (sigma-clipped mean)\n",
    "5. Post-processing (gradient removal, star control, color stretch)\n",
    "\n",
    "**Dataset:** Andromeda (M31) from Nebula Photos"
   ],
   "id": "fd8fc91229205d26"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T17:10:53.504857Z",
     "start_time": "2025-12-09T17:10:49.633680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==============================================================================\n",
    "# Part 0: Setup and Requirements\n",
    "# ==============================================================================\n",
    "\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import rawpy\n",
    "from astropy.io import fits\n",
    "from astropy import units as u\n",
    "from ccdproc import CCDData, ImageFileCollection\n",
    "import ccdproc as ccdp\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from astroalign import register\n",
    "from astropy.stats import sigma_clip\n",
    "from scipy.ndimage import median_filter, gaussian_filter\n",
    "from skimage.restoration import denoise_bilateral\n",
    "from skimage.exposure import rescale_intensity\n",
    "import matplotlib.pyplot as plt\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import gc\n",
    "\n",
    "req_path = Path(\"requirements.txt\")\n",
    "print(\"Using requirements file at:\", req_path.resolve())\n",
    "\n",
    "if not req_path.exists():\n",
    "    raise FileNotFoundError(\"requirements.txt not found next to this notebook.\")\n",
    "\n",
    "# Jupyter magic: installs into the current kernel\n",
    "%pip install -r requirements.txt"
   ],
   "id": "f6cc7761c16803cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using requirements file at: C:\\Users\\jalin\\Documents\\Fall 2025\\cs570\\Team Project\\GitHub\\Astrophotography\\Astrophotography\\requirements.txt\n",
      "Requirement already satisfied: astropy==7.1.0 in c:\\users\\jalin\\documents\\fall 2025\\cs570\\team project\\github\\astrophotography\\astrophotography\\.venv\\lib\\site-packages (from -r requirements.txt (line 1)) (7.1.0)\n",
      "Requirement already satisfied: astropy-iers-data==0.2025.10.6.0.35.25 in c:\\users\\jalin\\documents\\fall 2025\\cs570\\team project\\github\\astrophotography\\astrophotography\\.venv\\lib\\site-packages (from -r requirements.txt (line 2)) (0.2025.10.6.0.35.25)\n",
      "Requirement already satisfied: numpy==2.3.3 in c:\\users\\jalin\\documents\\fall 2025\\cs570\\team project\\github\\astrophotography\\astrophotography\\.venv\\lib\\site-packages (from -r requirements.txt (line 3)) (2.3.3)\n",
      "Requirement already satisfied: packaging==25.0 in c:\\users\\jalin\\documents\\fall 2025\\cs570\\team project\\github\\astrophotography\\astrophotography\\.venv\\lib\\site-packages (from -r requirements.txt (line 4)) (25.0)\n",
      "Requirement already satisfied: pyerfa==2.0.1.5 in c:\\users\\jalin\\documents\\fall 2025\\cs570\\team project\\github\\astrophotography\\astrophotography\\.venv\\lib\\site-packages (from -r requirements.txt (line 5)) (2.0.1.5)\n",
      "Requirement already satisfied: PyYAML==6.0.3 in c:\\users\\jalin\\documents\\fall 2025\\cs570\\team project\\github\\astrophotography\\astrophotography\\.venv\\lib\\site-packages (from -r requirements.txt (line 6)) (6.0.3)\n",
      "Requirement already satisfied: setuptools==78.1.1 in c:\\users\\jalin\\documents\\fall 2025\\cs570\\team project\\github\\astrophotography\\astrophotography\\.venv\\lib\\site-packages (from -r requirements.txt (line 7)) (78.1.1)\n",
      "Requirement already satisfied: wheel==0.45.1 in c:\\users\\jalin\\documents\\fall 2025\\cs570\\team project\\github\\astrophotography\\astrophotography\\.venv\\lib\\site-packages (from -r requirements.txt (line 8)) (0.45.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T17:10:53.515494Z",
     "start_time": "2025-12-09T17:10:53.508305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==============================================================================\n",
    "# Part 1: Configuration & Path Setup\n",
    "# ==============================================================================\n",
    "\n",
    "# 1. Define Base Paths\n",
    "# The script assumes your CR2s are in 'astro_data/cr2_raw'\n",
    "base_dir = Path(\"./data\")\n",
    "raw_dir = (\n",
    "    base_dir / \"raw_data\"\n",
    ")  # Create dir for raw photos with folder of the frame types\n",
    "fits_dir = base_dir / \"fits_data/\"  # Create dir for fits data to be saved\n",
    "\n",
    "# 2. Define FITS Directories (Script will create these)\n",
    "fits_bias_dir = fits_dir / \"bias/\"\n",
    "fits_dark_dir = fits_dir / \"dark/\"\n",
    "fits_flat_dir = fits_dir / \"flat/\"\n",
    "fits_light_dir = fits_dir / \"light/\"\n",
    "master_dir = fits_dir / \"master_frames\"\n",
    "calibrated_dir = fits_dir / \"calibrated_lights\"\n",
    "\n",
    "# 3. Define FITS Header Keyword for Exposure Time\n",
    "# We set this to 'EXPTIME'. The conversion step (Part 1) will\n",
    "# create this keyword, and the calibration step (Part 2) will read it.\n",
    "EXPOSURE_KEY = \"EXPTIME\"\n",
    "\n",
    "# Naming convention for the final master frames\n",
    "MASTER_BIAS_FILE = master_dir / \"MasterBias.fit\"\n",
    "MASTER_DARK_FILE = master_dir / \"MasterDark.fit\"\n",
    "MASTER_FLAT_FILE = master_dir / \"MasterFlat.fit\"\n",
    "\n",
    "\n",
    "aligned_dir = fits_dir / \"aligned_lights\"\n",
    "aligned_dir.mkdir(exist_ok=True)\n",
    "\n",
    "stack_output = fits_dir / \"stacked\"\n",
    "stack_output.mkdir(exist_ok=True)"
   ],
   "id": "a19db82f3647a7c5",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T17:10:53.533853Z",
     "start_time": "2025-12-09T17:10:53.515494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==============================================================================\n",
    "# Part 2: Preview Window Functions\n",
    "# ==============================================================================\n",
    "\n",
    "def show_step_preview(prev_image_path, curr_image_path, window_title=\"Step Preview\"):\n",
    "    \"\"\"\n",
    "    Open a Tkinter window showing two images side-by-side:\n",
    "    - Left:  previous step\n",
    "    - Right: current step\n",
    "    \"\"\"\n",
    "\n",
    "    # Create main window\n",
    "    root = tk.Tk()\n",
    "    root.title(window_title)\n",
    "\n",
    "    # Main frame\n",
    "    main_frame = tk.Frame(root)\n",
    "    main_frame.pack(side=tk.TOP, fill=tk.BOTH, expand=True)\n",
    "\n",
    "    # Left and right frames\n",
    "    left_frame = tk.Frame(main_frame)\n",
    "    right_frame = tk.Frame(main_frame)\n",
    "\n",
    "    left_frame.pack(side=tk.LEFT, padx=10, pady=10)\n",
    "    right_frame.pack(side=tk.LEFT, padx=10, pady=10)\n",
    "\n",
    "    # Load images with PIL\n",
    "    prev_img = Image.open(prev_image_path)\n",
    "    curr_img = Image.open(curr_image_path)\n",
    "\n",
    "    # Optional: simple resize to avoid enormous windows (adjust as needed)\n",
    "    max_width = 600\n",
    "    max_height = 600\n",
    "\n",
    "# ==============================================================================\n",
    "\n",
    "    def _resize_if_needed(img):\n",
    "        w, h = img.size\n",
    "        scale = min(max_width / w, max_height / h, 1.0)\n",
    "        if scale < 1.0:\n",
    "            new_size = (int(w * scale), int(h * scale))\n",
    "            return img.resize(new_size, Image.LANCZOS)\n",
    "        return img\n",
    "\n",
    "    prev_img = _resize_if_needed(prev_img)\n",
    "    curr_img = _resize_if_needed(curr_img)\n",
    "\n",
    "    prev_tk = ImageTk.PhotoImage(prev_img)\n",
    "    curr_tk = ImageTk.PhotoImage(curr_img)\n",
    "\n",
    "    # Labels\n",
    "    left_label_title = tk.Label(left_frame, text=\"Previous Step\")\n",
    "    left_label_title.pack()\n",
    "    left_label = tk.Label(left_frame, image=prev_tk)\n",
    "    left_label.image = prev_tk  # keep reference\n",
    "    left_label.pack()\n",
    "\n",
    "    right_label_title = tk.Label(right_frame, text=\"Current Step\")\n",
    "    right_label_title.pack()\n",
    "    right_label = tk.Label(right_frame, image=curr_tk)\n",
    "    right_label.image = curr_tk  # keep reference\n",
    "    right_label.pack()\n",
    "\n",
    "    # Start event loop\n",
    "    root.mainloop()\n",
    "\n",
    "    # Clean up\n",
    "    gc.collect()\n",
    "\n",
    "# ==============================================================================\n",
    "\n",
    "# Make sure fits_dir exists even if this cell is run standalone\n",
    "base_dir = Path(\"./data\")\n",
    "fits_dir = base_dir / \"fits_data\"\n",
    "\n",
    "preview_dir = fits_dir / \"previews\"\n",
    "preview_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def stretch_for_preview(data, low_pct=0.5, high_pct=99.5):\n",
    "    \"\"\"\n",
    "    Percentile-based stretch for display only.\n",
    "    Similar to an auto STF in astro software.\n",
    "\n",
    "    low_pct  : lower percentile to clip (e.g., 0.5)\n",
    "    high_pct : upper percentile to clip (e.g., 99.5)\n",
    "    \"\"\"\n",
    "    data = np.asarray(data, dtype=np.float32)\n",
    "\n",
    "    # Handle NaNs/Infs\n",
    "    finite = data[np.isfinite(data)]\n",
    "    if finite.size == 0:\n",
    "        return np.zeros_like(data, dtype=np.float32)\n",
    "\n",
    "    low = np.percentile(finite, low_pct)\n",
    "    high = np.percentile(finite, high_pct)\n",
    "\n",
    "    if high <= low:\n",
    "        high = low + 1e-6\n",
    "\n",
    "    stretched = (data - low) / (high - low)\n",
    "    stretched = np.clip(stretched, 0.0, 1.0)\n",
    "    return stretched\n",
    "\n",
    "# ==============================================================================\n",
    "\n",
    "def make_preview_png(fits_path, png_path):\n",
    "    \"\"\"\n",
    "    Load a FITS file, apply stretch_for_preview, save a grayscale PNG.\n",
    "    This does NOT affect the science pipeline, only the previews.\n",
    "    \"\"\"\n",
    "    fits_path = Path(fits_path)\n",
    "    png_path = Path(png_path)\n",
    "\n",
    "    if not fits_path.exists():\n",
    "        print(\"FITS file not found:\", fits_path)\n",
    "        return\n",
    "\n",
    "    data = fits.getdata(fits_path)\n",
    "\n",
    "    # Apply display stretch\n",
    "    data_disp = stretch_for_preview(data)\n",
    "\n",
    "    plt.imsave(png_path, data_disp, cmap=\"gray\")\n",
    "    print(\"Saved preview PNG:\", png_path)\n",
    "\n",
    "# ==============================================================================\n",
    "\n",
    "def _center_crop(data, frac=0.6):\n",
    "    \"\"\"\n",
    "    Crop the array to the central region.\n",
    "    frac is the fraction of the smaller dimension to keep (0<frac<=1).\n",
    "    \"\"\"\n",
    "    h, w = data.shape\n",
    "    size = int(min(h, w) * frac)\n",
    "    y0 = (h - size) // 2\n",
    "    x0 = (w - size) // 2\n",
    "    return data[y0:y0+size, x0:x0+size]\n",
    "\n",
    "# ==============================================================================\n",
    "\n",
    "def stretch_pair_for_preview(data1, data2, low_pct=0.5, high_pct=99.5, crop=True):\n",
    "    \"\"\"\n",
    "    Take two 2D arrays (same shape), optionally center-crop them,\n",
    "    and apply the SAME percentile stretch to both.\n",
    "    Returns (disp1, disp2) scaled to [0,1].\n",
    "    \"\"\"\n",
    "    d1 = np.asarray(data1, dtype=np.float32)\n",
    "    d2 = np.asarray(data2, dtype=np.float32)\n",
    "\n",
    "    if crop:\n",
    "        d1 = _center_crop(d1)\n",
    "        d2 = _center_crop(d2)\n",
    "\n",
    "    # Combine finite values from both for joint percentiles\n",
    "    finite = np.concatenate([\n",
    "        d1[np.isfinite(d1)].ravel(),\n",
    "        d2[np.isfinite(d2)].ravel()\n",
    "    ])\n",
    "\n",
    "    if finite.size == 0:\n",
    "        z = np.zeros_like(d1, dtype=np.float32)\n",
    "        return z, z\n",
    "\n",
    "    low = np.percentile(finite, low_pct)\n",
    "    high = np.percentile(finite, high_pct)\n",
    "    if high <= low:\n",
    "        high = low + 1e-6\n",
    "\n",
    "# ==============================================================================\n",
    "\n",
    "    def _stretch(d):\n",
    "        x = (d - low) / (high - low)\n",
    "        return np.clip(x, 0.0, 1.0)\n",
    "\n",
    "    return _stretch(d1), _stretch(d2)\n",
    "\n"
   ],
   "id": "bead7a9ca9a22a0f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T17:13:07.432731Z",
     "start_time": "2025-12-09T17:10:53.539952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==============================================================================\n",
    "# PART 3: CR2 TO FITS CONVERSION & Calibration\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "def convert_cr2_to_fits(raw_src_dir, fits_dest_dir, image_type):\n",
    "    \"\"\"\n",
    "    Converts all CR2 files in a source directory to FITS files\n",
    "    in a destination directory using rawpy.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Converting {image_type} CR2s to FITS ---\")\n",
    "    raw_src_dir = Path(raw_src_dir)\n",
    "    fits_dest_dir = Path(fits_dest_dir)\n",
    "\n",
    "    # Create the destination directory if it doesn't exist\n",
    "    fits_dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    cr2_files = list(raw_src_dir.glob(\"*.CR2\")) + list(raw_src_dir.glob(\"*.cr2\"))\n",
    "    if not cr2_files:\n",
    "        print(f\"Warning: No CR2 files found in {raw_src_dir}\")\n",
    "        return\n",
    "\n",
    "    for cr2_path in tqdm(cr2_files, desc=f\"Converting {image_type}\"):\n",
    "        try:\n",
    "            with rawpy.imread(str(cr2_path)) as raw:\n",
    "                # Extract the raw, 16-bit sensor data (Bayered)\n",
    "                # This is what we want for calibration\n",
    "\n",
    "                raw_image = raw.raw_image_visible.astype(np.uint16)\n",
    "\n",
    "                # Extract essential metadata\n",
    "                iso = 200\n",
    "                exposure = 25\n",
    "                # timestamp_obj = datetime.fromtimestamp(raw.timestamp)\n",
    "                # timestamp_iso = timestamp_obj.isoformat()\n",
    "\n",
    "                # Create a FITS Header\n",
    "                header = fits.Header()\n",
    "                header[\"IMAGETYP\"] = (image_type, \"Image type\")\n",
    "                header[EXPOSURE_KEY] = (exposure, \"Exposure time in seconds\")\n",
    "                header[\"ISO\"] = (iso, \"Camera ISO setting\")\n",
    "                # header['DATE-OBS'] = (timestamp_iso, 'Observation start time')\n",
    "\n",
    "                # Create a FITS HDU (Header Data Unit)\n",
    "                hdu = fits.PrimaryHDU(data=raw_image, header=header)\n",
    "\n",
    "                # Write the FITS file\n",
    "                fits_filename = cr2_path.stem + \".fit\"\n",
    "                hdu.writeto(fits_dest_dir / fits_filename, overwrite=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError converting {cr2_path.name}: {e}\")\n",
    "\n",
    "    print(f\"\\nCompleted conversion for {image_type}.\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# MASTER FRAME CREATION & CALIBRATION\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "def create_master_bias():\n",
    "    if MASTER_BIAS_FILE.exists():\n",
    "        print(f\"\\nLoading existing Master Bias from: {MASTER_BIAS_FILE.name}\")\n",
    "        return ccdp.CCDData.read(MASTER_BIAS_FILE, unit=u.adu)\n",
    "\n",
    "    print(\n",
    "        f\"\\n--- 1. Creating Master Bias Frame from {len(list(fits_bias_dir.glob('*.fit')))} files ---\"\n",
    "    )\n",
    "    ifc = ImageFileCollection(fits_bias_dir)\n",
    "\n",
    "    # Get a list of the FULL PATHS to the bias files\n",
    "    files_to_combine = ifc.files_filtered(include_path=True)\n",
    "\n",
    "    if not files_to_combine:\n",
    "        print(f\"Error: No FITS files found in {fits_bias_dir}\")\n",
    "        sys.exit()\n",
    "\n",
    "    # Combine all 50 bias frames\n",
    "    master_bias = ccdp.combine(\n",
    "        files_to_combine,\n",
    "        method=\"median\",\n",
    "        unit=u.adu,\n",
    "        mem_limit=2.5e9,\n",
    "        sigma_clip=True,\n",
    "        sigma_clip_low_thresh=5,\n",
    "        sigma_clip_high_thresh=5,\n",
    "    )\n",
    "\n",
    "    master_bias.write(MASTER_BIAS_FILE, overwrite=True)\n",
    "    print(f\"Master Bias saved to: {MASTER_BIAS_FILE.name}\")\n",
    "    return master_bias\n",
    "\n",
    "\n",
    "def create_master_dark(master_bias):\n",
    "    if MASTER_DARK_FILE.exists():\n",
    "        print(f\"\\nLoading existing Master Dark from: {MASTER_DARK_FILE.name}\")\n",
    "        return ccdp.CCDData.read(MASTER_DARK_FILE, unit=u.adu)\n",
    "\n",
    "    print(\n",
    "        f\"\\n--- 2. Creating Master Dark Frame from {len(list(fits_dark_dir.glob('*.fit')))} files ---\"\n",
    "    )\n",
    "\n",
    "    if not any(fits_dark_dir.glob(\"*.fit\")):\n",
    "        print(f\"Error: No FITS files found in {fits_dark_dir}.\")\n",
    "        sys.exit()\n",
    "\n",
    "    ifc = ImageFileCollection(fits_dark_dir, keywords=[EXPOSURE_KEY])\n",
    "\n",
    "    # First, check the exposure times from the summary\n",
    "    exp_times = set(ifc.summary[EXPOSURE_KEY])\n",
    "\n",
    "    if len(exp_times) == 0:\n",
    "        print(f\"\\n\\nCRITICAL ERROR in 'create_master_dark':\")\n",
    "        print(\n",
    "            f\"Error: No '{EXPOSURE_KEY}' keyword found in any FITS files in {fits_dark_dir}.\"\n",
    "        )\n",
    "        print(\"This means the 'rawpy' conversion failed to get exposure times.\")\n",
    "        sys.exit()\n",
    "\n",
    "    if len(exp_times) > 1:\n",
    "        print(f\"\\n\\nCRITICAL ERROR in 'create_master_dark':\")\n",
    "        print(\n",
    "            f\"Error: Your dark frames have multiple different exposure times: {exp_times}\"\n",
    "        )\n",
    "        print(\n",
    "            \"A Master Dark can only be created from darks with the *exact same* exposure time.\"\n",
    "        )\n",
    "        sys.exit()\n",
    "\n",
    "    dark_exposure_time = list(exp_times)[0] * u.s\n",
    "    print(f\"Found dark frames with a single exposure time: {dark_exposure_time}\")\n",
    "\n",
    "    dark_frames_to_combine = []\n",
    "\n",
    "    # Get full paths and loop explicitly\n",
    "    files_to_load = ifc.files_filtered(include_path=True)\n",
    "    for f_path in files_to_load:\n",
    "        dark_frame = CCDData.read(f_path, unit=u.adu)\n",
    "        dark_subtracted = ccdp.subtract_bias(dark_frame, master_bias)\n",
    "        dark_frames_to_combine.append(dark_subtracted)\n",
    "\n",
    "    master_dark = ccdp.combine(\n",
    "        dark_frames_to_combine,\n",
    "        method=\"median\",\n",
    "        unit=u.adu,\n",
    "        mem_limit=2.5e9,\n",
    "        sigma_clip=True,\n",
    "        sigma_clip_low_thresh=5,\n",
    "        sigma_clip_high_thresh=5,\n",
    "    )\n",
    "\n",
    "    master_dark.header[EXPOSURE_KEY] = (\n",
    "        dark_exposure_time.value,\n",
    "        \"Exposure time of master dark\",\n",
    "    )\n",
    "    master_dark.write(MASTER_DARK_FILE, overwrite=True)\n",
    "    print(f\"Master Dark saved to: {MASTER_DARK_FILE.name}\")\n",
    "    return master_dark\n",
    "\n",
    "\n",
    "def create_master_flat(master_bias, master_dark):\n",
    "    if MASTER_FLAT_FILE.exists():\n",
    "        print(f\"\\nLoading existing Master Dark from: {MASTER_FLAT_FILE.name}\")\n",
    "        return ccdp.CCDData.read(MASTER_FLAT_FILE, unit=u.adu)\n",
    "\n",
    "    print(\n",
    "        f\"\\n--- 3. Creating Master Flat Frame from {len(list(fits_flat_dir.glob('*.fit')))} files ---\"\n",
    "    )\n",
    "    ifc = ImageFileCollection(fits_flat_dir)\n",
    "\n",
    "    flat_frames_to_combine = []\n",
    "    master_dark_exp = master_dark.header[EXPOSURE_KEY] * u.s\n",
    "\n",
    "    files_to_load = ifc.files_filtered(include_path=True)\n",
    "    for f_path in files_to_load:\n",
    "        flat_frame = CCDData.read(f_path, unit=u.adu)\n",
    "        flat_exposure_time = flat_frame.header[EXPOSURE_KEY] * u.s\n",
    "        flat_subtracted = ccdp.subtract_bias(flat_frame, master_bias)\n",
    "        flat_corrected = ccdp.subtract_dark(\n",
    "            flat_subtracted,\n",
    "            master_dark,\n",
    "            dark_exposure=master_dark_exp,\n",
    "            data_exposure=flat_exposure_time,\n",
    "            scale=True,\n",
    "        )\n",
    "        flat_frames_to_combine.append(flat_corrected)\n",
    "\n",
    "    master_flat = ccdp.combine(\n",
    "        flat_frames_to_combine,\n",
    "        method=\"median\",\n",
    "        unit=u.adu,\n",
    "        mem_limit=2.5e9,\n",
    "        sigma_clip=True,\n",
    "        sigma_clip_low_thresh=5,\n",
    "        sigma_clip_high_thresh=5,\n",
    "    )\n",
    "\n",
    "    master_flat.data /= np.median(master_flat.data)\n",
    "    master_flat.write(MASTER_FLAT_FILE, overwrite=True)\n",
    "    print(f\"Master Flat saved to: {MASTER_FLAT_FILE.name}\")\n",
    "    return master_flat\n",
    "\n",
    "\n",
    "def process_light_frames(master_bias, master_dark, master_flat):\n",
    "    print(\n",
    "        f\"\\n--- 4. Calibrating {len(list(fits_light_dir.glob('*.fit')))} Light Frames ---\"\n",
    "    )\n",
    "    ifc = ImageFileCollection(fits_light_dir, keywords=[EXPOSURE_KEY])\n",
    "\n",
    "    calibrated_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    master_dark_exp = master_dark.header[EXPOSURE_KEY] * u.s\n",
    "\n",
    "    files_to_load = ifc.files_filtered(include_path=True)\n",
    "    for f_path in files_to_load:\n",
    "        raw_light = CCDData.read(f_path, unit=u.adu)\n",
    "        light_exposure_time = raw_light.header[EXPOSURE_KEY] * u.s\n",
    "\n",
    "        # 1. Subtract Bias\n",
    "        calibrated_light = ccdp.subtract_bias(raw_light, master_bias)\n",
    "\n",
    "        # 2. Subtract Scaled Dark\n",
    "        calibrated_light = ccdp.subtract_dark(\n",
    "            calibrated_light,\n",
    "            master_dark,\n",
    "            dark_exposure=master_dark_exp,\n",
    "            data_exposure=light_exposure_time,\n",
    "            scale=True,\n",
    "        )\n",
    "\n",
    "        # 3. Apply Flat-Field Correction\n",
    "        calibrated_light = ccdp.flat_correct(calibrated_light, master_flat)\n",
    "\n",
    "        output_filename = f\"calibrated_{os.path.basename(f_path)}\"\n",
    "        calibrated_light.write(calibrated_dir / output_filename, overwrite=True)\n",
    "\n",
    "    print(f\"\\nCompleted calibration of all light frames.\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# MAIN EXECUTION BLOCK\n",
    "# ==============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Check if the raw directories exist\n",
    "    if not raw_dir.exists():\n",
    "        print(f\"Error: Raw data directory not found at {raw_dir}\")\n",
    "        print(\"Please create the directory structure as described.\")\n",
    "        sys.exit()\n",
    "\n",
    "    # --- RUN PART 1: CONVERSION ---\n",
    "    # Create all FITS directories first\n",
    "    for d in [\n",
    "        fits_bias_dir,\n",
    "        fits_dark_dir,\n",
    "        fits_flat_dir,\n",
    "        fits_light_dir,\n",
    "        master_dir,\n",
    "        calibrated_dir,\n",
    "    ]:\n",
    "        d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # # Convert all CR2 files to FITS (Comment out lines below when you add files to your dir)\n",
    "    convert_cr2_to_fits(raw_dir / 'bias/', fits_bias_dir, 'BIAS')\n",
    "    convert_cr2_to_fits(raw_dir / 'dark/', fits_dark_dir, 'DARK')\n",
    "    convert_cr2_to_fits(raw_dir / 'flat/', fits_flat_dir, 'FLAT')\n",
    "    convert_cr2_to_fits(raw_dir / 'light/', fits_light_dir, 'LIGHT')\n",
    "\n",
    "    print(\"\\n*** CR2 to FITS conversion complete! ***\")\n",
    "\n",
    "    # --- RUN PART 2: CALIBRATION ---\n",
    "    print(\"\\n*** Starting calibration process... ***\")\n",
    "\n",
    "    # try:\n",
    "    # 1. Create Master Calibration Frames\n",
    "    master_bias = create_master_bias()\n",
    "    master_dark = create_master_dark(master_bias)\n",
    "    master_flat = create_master_flat(master_bias, master_dark)\n",
    "\n",
    "    # 2. Calibrate the Science Frames\n",
    "    process_light_frames(master_bias, master_dark, master_flat)\n",
    "\n",
    "    print(\"\\n*** Full data reduction complete! ***\")\n",
    "    print(f\"Calibrated light frames are saved in: {calibrated_dir}\")\n",
    "\n",
    "    # except Exception as e:\n",
    "    #     print(f\"\\nAn error occurred during calibration: {e}\")"
   ],
   "id": "2ce12033091a247d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Converting BIAS CR2s to FITS ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting BIAS: 100%|██████████| 74/74 [00:50<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completed conversion for BIAS.\n",
      "\n",
      "--- Converting DARK CR2s to FITS ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting DARK: 100%|██████████| 34/34 [00:23<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completed conversion for DARK.\n",
      "\n",
      "--- Converting FLAT CR2s to FITS ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting FLAT: 100%|██████████| 60/60 [00:44<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completed conversion for FLAT.\n",
      "\n",
      "--- Converting LIGHT CR2s to FITS ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting LIGHT: 100%|██████████| 6/6 [00:04<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completed conversion for LIGHT.\n",
      "\n",
      "*** CR2 to FITS conversion complete! ***\n",
      "\n",
      "*** Starting calibration process... ***\n",
      "\n",
      "Loading existing Master Bias from: MasterBias.fit\n",
      "INFO: using the unit adu passed to the FITS reader instead of the unit adu in the FITS file. [astropy.nddata.ccddata]\n",
      "\n",
      "Loading existing Master Dark from: MasterDark.fit\n",
      "INFO: using the unit adu passed to the FITS reader instead of the unit adu in the FITS file. [astropy.nddata.ccddata]\n",
      "\n",
      "Loading existing Master Dark from: MasterFlat.fit\n",
      "INFO: using the unit adu passed to the FITS reader instead of the unit adu in the FITS file. [astropy.nddata.ccddata]\n",
      "\n",
      "--- 4. Calibrating 3 Light Frames ---\n",
      "\n",
      "Completed calibration of all light frames.\n",
      "\n",
      "*** Full data reduction complete! ***\n",
      "Calibrated light frames are saved in: data\\fits_data\\calibrated_lights\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T17:13:15.051669Z",
     "start_time": "2025-12-09T17:13:07.464254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Preview: Compare raw light vs calibrated light\n",
    "# PREVIEW A: Raw light vs Calibrated light\n",
    "\n",
    "# Pick the first raw light FITS\n",
    "# PREVIEW A: Raw light vs Calibrated light (with joint stretch and crop)\n",
    "\n",
    "raw_files = sorted(fits_light_dir.glob(\"*.fit\"))\n",
    "if not raw_files:\n",
    "    print(\"No raw FITS lights found in:\", fits_light_dir)\n",
    "else:\n",
    "    raw_fits = raw_files[0]\n",
    "    print(\"Using raw FITS:\", raw_fits.name)\n",
    "\n",
    "    calibrated_fits = calibrated_dir / f\"calibrated_{raw_fits.name}\"\n",
    "    if not calibrated_fits.exists():\n",
    "        print(\"Matching calibrated FITS not found:\", calibrated_fits)\n",
    "    else:\n",
    "        print(\"Matching calibrated FITS:\", calibrated_fits.name)\n",
    "\n",
    "        raw_png = preview_dir / \"raw_light_preview.png\"\n",
    "        cal_png = preview_dir / \"calibrated_for_stack_preview.png\"\n",
    "\n",
    "        # Load both, apply shared stretch + crop, save PNGs\n",
    "        raw_data = fits.getdata(raw_fits)\n",
    "        cal_data = fits.getdata(calibrated_fits)\n",
    "\n",
    "        raw_disp, cal_disp = stretch_pair_for_preview(raw_data, cal_data)\n",
    "\n",
    "        plt.imsave(raw_png, raw_disp, cmap=\"gray\")\n",
    "        plt.imsave(cal_png, cal_disp, cmap=\"gray\")\n",
    "\n",
    "        show_step_preview(raw_png, cal_png, window_title=\"Raw vs Calibrated Light\")\n"
   ],
   "id": "4cce0537a9618c39",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using raw FITS: _MG_4378.fit\n",
      "Matching calibrated FITS: calibrated__MG_4378.fit\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T17:13:25.469833Z",
     "start_time": "2025-12-09T17:13:15.058702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==============================================================================\n",
    "# Part 4: Alignment\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "aligned_dir = fits_dir / \"aligned_lights\"\n",
    "aligned_dir.mkdir(exist_ok=True)\n",
    "\n",
    "def align_calibrated_frames():\n",
    "    print(\"\\n--- Aligning Calibrated Frames ---\")\n",
    "\n",
    "    cal_files = sorted(list(calibrated_dir.glob(\"*.fit\")))\n",
    "    if len(cal_files) < 2:\n",
    "        print(\"Need at least two frames to align!\")\n",
    "        return\n",
    "\n",
    "    # Reference frame\n",
    "    ref_data = fits.getdata(cal_files[0])\n",
    "    ref_header = fits.getheader(cal_files[0])\n",
    "\n",
    "    # Fix endian for reference\n",
    "    ref_data = np.asarray(ref_data, dtype=ref_data.dtype.newbyteorder('='))\n",
    "\n",
    "    for f in tqdm(cal_files, desc=\"Aligning frames\"):\n",
    "        data = fits.getdata(f)\n",
    "\n",
    "        # Fix endian for each image\n",
    "        data = np.asarray(data, dtype=data.dtype.newbyteorder('='))\n",
    "\n",
    "        try:\n",
    "            aligned, footprint = register(data, ref_data)\n",
    "        except Exception as e:\n",
    "            print(f\"Alignment failed for {f}: {e}\")\n",
    "            continue\n",
    "\n",
    "        out_file = aligned_dir / f\"aligned_{f.name}\"\n",
    "        fits.writeto(out_file, aligned, ref_header, overwrite=True)\n",
    "\n",
    "    print(\"Alignment completed!\")\n",
    "\n",
    "align_calibrated_frames()"
   ],
   "id": "48dd0097ebae9752",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Aligning Calibrated Frames ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aligning frames: 100%|██████████| 3/3 [00:10<00:00,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alignment completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T17:13:27.386954Z",
     "start_time": "2025-12-09T17:13:25.471432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==============================================================================\n",
    "# Part 5: Stacking\n",
    "# ==============================================================================\n",
    "\n",
    "def stack_aligned_frames():\n",
    "    print(\"\\n--- Stacking Aligned Frames ---\")\n",
    "\n",
    "    aligned_files = sorted(list(aligned_dir.glob(\"*.fit\")))\n",
    "    stack_list = []\n",
    "\n",
    "    for f in aligned_files:\n",
    "        img = fits.getdata(f).astype(float)\n",
    "        stack_list.append(img)\n",
    "\n",
    "    stack_array = np.array(stack_list)\n",
    "\n",
    "    # Sigma-clipped mean\n",
    "    clipped = sigma_clip(stack_array, sigma=3, axis=0)\n",
    "    stacked_image = np.mean(clipped.data, axis=0)\n",
    "\n",
    "    output_file = stack_output / \"stacked.fits\"\n",
    "    fits.writeto(output_file, stacked_image, overwrite=True)\n",
    "\n",
    "    print(f\"Stack saved to: {output_file}\")\n",
    "\n",
    "stack_aligned_frames()"
   ],
   "id": "b55ef72894d691ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Stacking Aligned Frames ---\n",
      "Stack saved to: data\\fits_data\\stacked\\stacked.fits\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T17:13:51.321146Z",
     "start_time": "2025-12-09T17:13:27.395157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# PREVIEW B: Calibrated & Aligned vs Stacked\n",
    "\n",
    "\n",
    "# Use one calibrated frame (e.g., middle of the list)\n",
    "calibrated_files = sorted(calibrated_dir.glob(\"calibrated_*.fit\"))\n",
    "if not calibrated_files:\n",
    "    print(\"No calibrated FITS files found in:\", calibrated_dir)\n",
    "else:\n",
    "    calibrated_fits = calibrated_files[len(calibrated_files) // 2]\n",
    "    print(\"Using calibrated FITS:\", calibrated_fits.name)\n",
    "\n",
    "    stacked_fits = stack_output / \"stacked.fits\"\n",
    "    if not stacked_fits.exists():\n",
    "        print(\"Stacked FITS not found:\", stacked_fits)\n",
    "    else:\n",
    "        print(\"Using stacked FITS:\", stacked_fits.name)\n",
    "\n",
    "        cal_png = preview_dir / \"calibrated_for_stack_preview.png\"\n",
    "        stacked_png = preview_dir / \"stacked_preview.png\"\n",
    "\n",
    "        # Load data\n",
    "        cal_data = fits.getdata(calibrated_fits)\n",
    "        stacked_data = fits.getdata(stacked_fits)\n",
    "\n",
    "        # Shared stretch using your existing helper\n",
    "        cal_disp, stacked_disp = stretch_pair_for_preview(cal_data, stacked_data)\n",
    "\n",
    "        # Save PNGs\n",
    "        plt.imsave(cal_png, cal_disp, cmap=\"gray\")\n",
    "        plt.imsave(stacked_png, stacked_disp, cmap=\"gray\")\n",
    "\n",
    "        # Show popup\n",
    "        show_step_preview(cal_png, stacked_png,\n",
    "                          window_title=\"Calibrated vs Aligned & Stacked\")\n"
   ],
   "id": "a67d5cfbeb12e7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using calibrated FITS: calibrated__MG_4380.fit\n",
      "Using stacked FITS: stacked.fits\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T17:14:11.858837Z",
     "start_time": "2025-12-09T17:13:51.321146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==============================================================================\n",
    "# Part 6: Post Processing\n",
    "# ==============================================================================\n",
    "\n",
    "base_dir = Path(\"./data\")\n",
    "fits_dir = base_dir / \"fits_data/\"\n",
    "stack_output = fits_dir / \"stacked\"\n",
    "\n",
    "input_stack_file = stack_output / \"stacked.fits\"\n",
    "output_fits = fits_dir / \"processed\" / \"processed_color.fit\"\n",
    "output_png = fits_dir / \"processed\" / \"processed_color.png\"\n",
    "output_fits.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "GRADIENT_MESH_SIZE = 128\n",
    "STRETCH_MULTIPLIER = 0.080   # Aggressive stretch to lift faint detail.\n",
    "STAR_REDUCTION_FACTOR = 0.5  # Keeps stars brighter (less reduction).\n",
    "SATURATION_BOOST = 2.0       # Vibrant color.\n",
    "BLUE_PUSH = 1.00\n",
    "RED_PUSH = 1.00\n",
    "BOOST_FACTOR = 0.5           # Local contrast applied to the STRETCHED image.\n",
    "BLACK_POINT = 1.5            # Crushes the lifted gray background to black.\n",
    "GAMMA = 0.8                  # Brightens mid-tones (galaxy structure) for final pop.\n",
    "\n",
    "\n",
    "def remove_gradient(img, mesh=GRADIENT_MESH_SIZE):\n",
    "    \"\"\"Dynamically estimate and subtract the background gradient (DBE).\"\"\"\n",
    "    h, w = img.shape\n",
    "    bg_model = np.zeros_like(img, dtype=np.float32)\n",
    "    for y in range(0, h, mesh):\n",
    "        for x in range(0, w, mesh):\n",
    "            tile = img[y:y+mesh, x:x+mesh]\n",
    "            bg = np.median(tile)\n",
    "            bg_model[y:y+mesh, x:x+mesh] = bg\n",
    "    bg_model = gaussian_filter(bg_model, sigma=mesh/2)\n",
    "    return img - bg_model\n",
    "\n",
    "\n",
    "def star_reduction(img, sigma=15, reduction_factor=STAR_REDUCTION_FACTOR):\n",
    "    \"\"\"Controls star size. Lower reduction_factor means brighter stars.\"\"\"\n",
    "    galaxy_model = gaussian_filter(img, sigma=sigma)\n",
    "    star_mask = img - galaxy_model\n",
    "    return img - (star_mask * reduction_factor)\n",
    "\n",
    "\n",
    "def run_post_processing():\n",
    "    print(\"\\n--- Starting Final Color Post-Processing ---\")\n",
    "\n",
    "\n",
    "    print(\"1. Loading and Demosaicing stacked data.\")\n",
    "    if not input_stack_file.exists():\n",
    "        print(f\"Error: Stacked file not found at {input_stack_file}\")\n",
    "        return\n",
    "\n",
    "    stacked_ccd = ccdp.CCDData.read(str(input_stack_file), unit=u.adu) # type: ignore\n",
    "    data = stacked_ccd.data.astype(np.float32)\n",
    "\n",
    "    # Assumes RGGB pattern for array slicing\n",
    "    try:\n",
    "        R = data[::2, ::2]\n",
    "        G = (data[::2, 1::2] + data[1::2, ::2]) / 2.0\n",
    "        B = data[1::2, 1::2]\n",
    "        color_image = np.dstack([R, G, B])\n",
    "        if color_image.ndim != 3 or color_image.shape[2] != 3:\n",
    "             raise ValueError(\"NumPy separation failed.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nCRITICAL ERROR: Demosaicing failed: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "    print(\"2. Removing gradients from each color channel.\")\n",
    "    img_detrended_r = remove_gradient(color_image[:, :, 0])\n",
    "    img_detrended_g = remove_gradient(color_image[:, :, 1])\n",
    "    img_detrended_b = remove_gradient(color_image[:, :, 2])\n",
    "    img_detrended_color = np.dstack([img_detrended_r, img_detrended_g, img_detrended_b])\n",
    "\n",
    "\n",
    "\n",
    "    print(\"3. Applying noise reduction and star reduction.\")\n",
    "    img_denoised = denoise_bilateral(\n",
    "        img_detrended_color, sigma_color=0.05, sigma_spatial=2, channel_axis=2\n",
    "    )\n",
    "    img_denoised = median_filter(img_denoised, size=3)\n",
    "\n",
    "    img_galaxy_dominant = np.zeros_like(img_denoised)\n",
    "    for i in range(3):\n",
    "        img_galaxy_dominant[:, :, i] = star_reduction(img_denoised[:, :, i])\n",
    "\n",
    "    # Clean up negatives before stretching\n",
    "    img_clean = img_galaxy_dominant - np.min(img_galaxy_dominant)\n",
    "\n",
    "\n",
    "    print(\"4. Applying aggressive non-linear stretch (Galaxy POP).\")\n",
    "    stretched = np.arcsinh(img_clean * STRETCH_MULTIPLIER)\n",
    "    img_contrast_base = stretched\n",
    "\n",
    "\n",
    "    print(\"5. Applying local contrast enhancement.\")\n",
    "    # Now that the image is stretched, we can safely use a higher BOOST_FACTOR\n",
    "    blurred_low_freq = gaussian_filter(img_contrast_base, sigma=30, axes=2)\n",
    "    high_freq_detail = img_contrast_base - blurred_low_freq\n",
    "\n",
    "    img_final_base = img_contrast_base + (high_freq_detail * BOOST_FACTOR)\n",
    "    img_balanced = img_final_base.copy()\n",
    "\n",
    "\n",
    "    print(\"6. Color balancing.\")\n",
    "    # Color balance applied to the stretched data\n",
    "    median_g = np.median(img_balanced[:, :, 1])\n",
    "    r_factor = median_g / np.median(img_balanced[:, :, 0])\n",
    "    b_factor = median_g / np.median(img_balanced[:, :, 2])\n",
    "\n",
    "    img_balanced[:, :, 0] *= r_factor * RED_PUSH\n",
    "    img_balanced[:, :, 2] *= b_factor * BLUE_PUSH\n",
    "\n",
    "\n",
    "    print(\"7. Boosting color saturation.\")\n",
    "    color_boosted = img_balanced.copy()\n",
    "    luminance = np.mean(color_boosted, axis=2, keepdims=True)\n",
    "    color_boosted = luminance + (color_boosted - luminance) * SATURATION_BOOST\n",
    "    color_boosted = np.clip(color_boosted, 0, None)\n",
    "\n",
    "\n",
    "    print(\"8. Adjusting contrast to crush blacks.\")\n",
    "\n",
    "    # Clip shadows to absolute zero (DARK BACKGROUND)\n",
    "    contrast_adjusted = color_boosted - BLACK_POINT\n",
    "    contrast_adjusted[contrast_adjusted < 0] = 0\n",
    "\n",
    "    # Rescale to 0-1 and apply Gamma (POP the galaxy)\n",
    "    max_val = np.max(contrast_adjusted)\n",
    "    if max_val > 0:\n",
    "        contrast_adjusted /= max_val\n",
    "    contrast_adjusted = np.power(contrast_adjusted, GAMMA)\n",
    "    color_boosted = contrast_adjusted\n",
    "\n",
    "\n",
    "    # 9. Save Results\n",
    "    print(\"9. Saving results.\")\n",
    "    stretched_norm = rescale_intensity(color_boosted, out_range=(0,1)) # type: ignore\n",
    "\n",
    "    hdu = fits.PrimaryHDU(color_boosted.astype(np.float32))\n",
    "    hdu.writeto(str(output_fits), overwrite=True)\n",
    "\n",
    "    plt.imsave(str(output_png), stretched_norm)\n",
    "\n",
    "    print(\"\\nColor Post-Processing complete!\")\n",
    "\n",
    "run_post_processing()"
   ],
   "id": "2556a5abb2e736f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Final Color Post-Processing ---\n",
      "1. Loading and Demosaicing stacked data.\n",
      "2. Removing gradients from each color channel.\n",
      "3. Applying noise reduction and star reduction.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 150\u001B[39m\n\u001B[32m    146\u001B[39m     plt.imsave(\u001B[38;5;28mstr\u001B[39m(output_png), stretched_norm)\n\u001B[32m    148\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mColor Post-Processing complete!\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m150\u001B[39m \u001B[43mrun_post_processing\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 84\u001B[39m, in \u001B[36mrun_post_processing\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m     80\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m3. Applying noise reduction and star reduction.\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     81\u001B[39m img_denoised = denoise_bilateral(\n\u001B[32m     82\u001B[39m     img_detrended_color, sigma_color=\u001B[32m0.05\u001B[39m, sigma_spatial=\u001B[32m2\u001B[39m, channel_axis=\u001B[32m2\u001B[39m\n\u001B[32m     83\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m84\u001B[39m img_denoised = \u001B[43mmedian_filter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg_denoised\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m3\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     86\u001B[39m img_galaxy_dominant = np.zeros_like(img_denoised)\n\u001B[32m     87\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[32m3\u001B[39m):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\Fall 2025\\cs570\\Team Project\\GitHub\\Astrophotography\\Astrophotography\\.venv\\Lib\\site-packages\\scipy\\ndimage\\_filters.py:2134\u001B[39m, in \u001B[36mmedian_filter\u001B[39m\u001B[34m(input, size, footprint, output, mode, cval, origin, axes)\u001B[39m\n\u001B[32m   2075\u001B[39m \u001B[38;5;129m@_ni_docstrings\u001B[39m.docfiller\n\u001B[32m   2076\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mmedian_filter\u001B[39m(\u001B[38;5;28minput\u001B[39m, size=\u001B[38;5;28;01mNone\u001B[39;00m, footprint=\u001B[38;5;28;01mNone\u001B[39;00m, output=\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   2077\u001B[39m                   mode=\u001B[33m\"\u001B[39m\u001B[33mreflect\u001B[39m\u001B[33m\"\u001B[39m, cval=\u001B[32m0.0\u001B[39m, origin=\u001B[32m0\u001B[39m, *, axes=\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m   2078\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   2079\u001B[39m \u001B[33;03m    Calculate a multidimensional median filter.\u001B[39;00m\n\u001B[32m   2080\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m   2132\u001B[39m \u001B[33;03m    >>> plt.show()\u001B[39;00m\n\u001B[32m   2133\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m2134\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_rank_filter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfootprint\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2135\u001B[39m \u001B[43m                        \u001B[49m\u001B[43morigin\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mmedian\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxes\u001B[49m\u001B[43m=\u001B[49m\u001B[43maxes\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\Fall 2025\\cs570\\Team Project\\GitHub\\Astrophotography\\Astrophotography\\.venv\\Lib\\site-packages\\scipy\\ndimage\\_filters.py:2021\u001B[39m, in \u001B[36m_rank_filter\u001B[39m\u001B[34m(input, rank, size, footprint, output, mode, cval, origin, operation, axes)\u001B[39m\n\u001B[32m   2019\u001B[39m         np.copyto(output, x_out, casting=\u001B[33m'\u001B[39m\u001B[33munsafe\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m   2020\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2021\u001B[39m     \u001B[43m_nd_image\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrank_filter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrank\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfootprint\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcval\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morigins\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2022\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m temp_needed:\n\u001B[32m   2023\u001B[39m     temp[...] = output\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T17:14:11.862852900Z",
     "start_time": "2025-12-09T17:00:59.475875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# PREVIEW C: Stacked vs Post Processed\n",
    "\n",
    "stacked_fits = stack_output / \"stacked.fits\"\n",
    "final_png = fits_dir / \"processed\" / \"processed_color.png\"\n",
    "\n",
    "if stacked_fits.exists() and final_png.exists():\n",
    "    stacked_png = preview_dir / \"stacked_preview.png\"\n",
    "\n",
    "    stacked_data = fits.getdata(stacked_fits)\n",
    "    stacked_disp, _ = stretch_pair_for_preview(stacked_data, stacked_data)  # just reuse stretch\n",
    "    plt.imsave(stacked_png, stacked_disp, cmap=\"gray\")\n",
    "\n",
    "    show_step_preview(stacked_png, final_png, window_title=\"Stacked vs Post Processed\")\n"
   ],
   "id": "dcc498fbd026a58e",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T17:14:11.863849700Z",
     "start_time": "2025-12-09T17:01:03.360809Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9972d471fcbecbfb",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
